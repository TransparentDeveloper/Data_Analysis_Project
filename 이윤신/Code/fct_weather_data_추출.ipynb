{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fct_weather_data_추출.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1-xAiUq0CWYLxQEyAzgScFHMrmW-olDea","authorship_tag":"ABX9TyMmP923zMdVilT6JM9uSueQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ACoZcpBZ03dC"},"outputs":[],"source":["import pandas as pd\n","import os"]},{"cell_type":"code","source":["def extraction(year,target):\n","  path = '/content/drive/MyDrive/2022_WeatherContest_Data/DataSet/fct_weather_data/'+str(year)\n","  area_list = os.listdir(path)\n","\n","  area_dic ={key:list() for key in area_list}\n","  for area in area_list:\n","    file_list = os.listdir(path+'/'+area+'/')\n","    for file in file_list:\n","      if '_3시간기온_' in file:\n","        res = pd.read_csv(path+'/'+area+'/'+file,encoding='cp949')\n","        area_dic[area].append(res)\n","\n","\n","  for area in area_list:\n","    length = len(area_dic[area])\n","    for i in range(length):\n","\n","      # 컬럼명 변경\n","      df=area_dic[area][i] # 약한 복사 (원본 데이터도 바뀜, 이름 편하게 쓰려고)\n","      df.columns = ['day','hour','forecast','val']\n","\n","      df.drop_duplicates(inplace=True)\n","\n","      # 'day' 컬럼에 Start 란 문자열이 들어간 행(월 구분 행) index 추출 \n","      idxs = df[df['day'].str.contains('Start')].index\n","\n","\n","      # 'month' 컬럼 추가 \n","      start_num = 0\n","      month = 1 \n","      df['month'] = 0\n","      for end_num in idxs:\n","        df.loc[start_num:end_num,'month']= str(month)\n","        month += 1\n","        start_num = end_num\n","      df.loc[start_num:,'month']= month\n","      del month\n","\n","\n","      # 'day' 컬럼에 Start 란 문자열이 들어간 행 삭제\n","      df.drop(idxs,axis=0,inplace=True)\n","\n","\n","      if(df['hour'].dtypes != 'float'):\n","        idx = df[df['hour']=='hour'].index\n","        df.drop(idx,axis=0,inplace=True)\n","\n","\n","      # 'hour' 컬럼은 현재 float 형(오전 2시는 200, 오후 2시는 1400 이래 표기중)\n","      # 'hour' 을 100으로 나눠서 최대 10의 자리 정수로 변환\n","      df['hour'] = df['hour'].astype(float)\n","      df['hour'] = df['hour']//100\n","\n","\n","\n","      df['forecast'] = df['forecast'].astype('float')\n","      # 'hour' 과 'forecast' 의 합이 9, 12, 15, 33, 36, 39 인 행만 추출 살림\n","      condition1 = (df['hour']+df['forecast']!=9)\n","      condition2 = (df['hour']+df['forecast']!=12)\n","      condition3 = (df['hour']+df['forecast']!=15)\n","      condition4 = (df['hour']+df['forecast']!=33)\n","      condition5 = (df['hour']+df['forecast']!=36)\n","      condition6 = (df['hour']+df['forecast']!=39)\n","      drop_idxs = df.loc[condition1 & condition2 & condition3 & condition4 & condition5 & condition6].index\n","      df.drop(drop_idxs,axis=0,inplace =True)\n","      \n","\n","      # 'when'컬럼 추가 예보 대상 시점 정보를 담음\n","      # 예보시점은 불필요\n","      df['when'] = df['hour']+df['forecast']\n","      df.drop('hour',axis=1,inplace =True)\n","\n","      new_columns = ['month','day','when','forecast','val']\n","      area_dic[area][i] = df[new_columns]\n","      del new_columns\n","      # 달,일,예보대상시점,몇시간전 예보인지 순으로 재정렬 & 인덱스 재설정\n","      df.sort_values(['month','day','when','forecast'],inplace=True)\n","      df.reset_index(drop=True, inplace=True)\n","\n","\n","  # regional_integration_df 딕셔너리 안에 지역별 outer join 된 dataframe이 들어감\n","  # 딕셔너리 키 값은 지역명\n","  regional_integration_df = {key:0 for key in area_list}\n","\n","\n","  for area in area_list:\n","    length = len(area_dic[area])\n","    if length == 0:\n","      continue\n","    res = area_dic[area][0].copy()\n","    for i in range(1,length):\n","      res = pd.merge(res,area_dic[area][i].copy(),how='outer',on=['month','day','when','forecast'])\n","    regional_integration_df[area]=res\n","\n","  # 관측소마다 내놓은 예보 값의 mean과 max를 구함\n","  for area in area_list: \n","    regional_integration_df[area].iloc[:,4:] = regional_integration_df[area].iloc[:,4:].astype('float')\n","    val_mean = regional_integration_df[area].iloc[:,4:].mean(axis='columns')\n","    # val_max = regional_integration_df[area].iloc[:,4:].max(axis=1)\n","    regional_integration_df[area][f'{target}_mean'] = val_mean\n","    # regional_integration_df[area][f'{target}_max'] = val_max\n","\n","    # 'yyyymmdd'컬럼 생성 (datetime 형식)\n","    regional_integration_df[area]['yyyymmdd'] = str(year)\n","    regional_integration_df[area]['yyyymmdd'] = regional_integration_df[area]['yyyymmdd'].str.cat(regional_integration_df[area]['month'].astype(str), sep='-')\n","    regional_integration_df[area]['yyyymmdd'] = regional_integration_df[area]['yyyymmdd'].str.cat(regional_integration_df[area]['day'].str.strip(), sep='-')\n","    \n","    # 사용할 컬럼만 추림 (['yyyymmdd''when','forecast','val_mean','val_max'])\n","    regional_integration_df[area] = regional_integration_df[area][['yyyymmdd','when','forecast',f'{target}_mean',\n","                                                                  #  f'{target}_max'\n","                                                                  ]]\n","\n","    # 병병원데이터에 붙힐 수 있도록 reshape\n","    regional_integration_df[area]['yyyymmdd'] = pd.to_datetime(regional_integration_df[area]['yyyymmdd'])\n","    regional_integration_df[area]  = regional_integration_df[area].groupby(['yyyymmdd','when'],as_index=False)[f'{target}_mean',\n","                                                                                                              #  f'{target}_max'\n","                                                                                                              ].mean()\n","    regional_integration_df[area] = regional_integration_df[area].pivot(index='yyyymmdd',columns=['when'],values=[f'{target}_mean',\n","                                                                                                                  # f'{target}_max'\n","                                                                                                                  ])\n","    regional_integration_df[area].columns = [col[0]+'_'+str(int(col[1])) for col in regional_integration_df[area].columns]\n","\n","    # 지역명도 column에 추가\n","    regional_integration_df[area]['area'] = area\n","\n","\n","  return regional_integration_df"],"metadata":{"id":"hdEZMsux1m9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["area_list = ['전북',\n"," '제주',\n"," '충남',\n"," '충북',\n"," '강원',\n"," '경기',\n"," '경남',\n"," '경북',\n"," '광주',\n"," '대구',\n"," '대전',\n"," '부산',\n"," '서울',\n"," '세종',\n"," '울산',\n"," '인천',\n"," '전남']\n","\n","\n","subject = ['3시간기온','습도','일최고기온','일최저기온','풍속','강수량','적설']\n","back = pd.read_csv('/content/drive/MyDrive/2022_WeatherContest_Data/DataSet/hospital_data/back_hospital_new.csv',index_col=0)\n","back.columns = ['yyyymmdd','area','sex','frequency']\n","\n","fct_final = []\n","\n","for sub in subject:\n","  \n","  res_sep_year = []\n","  res_df = pd.DataFrame()\n","\n","  for year in range(2012,2016+1):\n","    # extraction() 에 연도와 목표 data의 이름을 넣으면 지역별로 정리된 dictionary 반환\n","    # res_sep_year 는 시간별로 정리된 dictionay list (인덱스 0 은 2012 , 인덱스 5는 2016)\n","    \n","    res_sep_year.append(extraction(year,sub))\n","    \n","    for area in area_list:\n","      # 각 지역별로 내일 예보는 한칸씩 내림\n","      res_sep_year[year-2012][area].iloc[:,3:6] = res_sep_year[year-2012][area].iloc[:,3:6].shift(periods = 1 ,axis = 0)\n","      # 시계열로 데이터 보간\n","      res_sep_year[year-2012][area].iloc[:,0:6] = res_sep_year[year-2012][area].iloc[:,0:6].interpolate(method='time')\n","      res_sep_year[year-2012][area].iloc[:,0:6] = res_sep_year[year-2012][area].iloc[:,0:6].interpolate(method='time',limit_direction='backward')\n","      # 지역별로 나눠진 df 하나로 합치기 (pre_merge)\n","      res_df = pd.concat([res_df,res_sep_year[year-2012][area]],axis = 0)\n","\n","  # 시계열 인덱스로부터 'yyyymmdd' 칼럼 추출\n","  res_df['yyyymmdd'] = res_df.index\n","  # 'yyyymmdd'를 back의 'yyyymmdd' 형식과 일치시킴\n","  res_df['yyyymmdd'] = res_df['yyyymmdd'].astype(str)\n","  res_df['yyyymmdd'] = res_df['yyyymmdd'].str.replace(pat=r'-', repl=r'', regex=True)\n","  res_df['yyyymmdd'] = res_df['yyyymmdd'].astype(int)\n","  # res 인덱스를 일반적인 색인으로 변환 (0,1,2,3,...) \n","  res_df.index = [i for i in range(len(res_df))]  \n","\n","  fct_final.append(res_df)\n","\n","# 주제별로 나눠진 df 하나로 합치기 (pre_merge)\n","pre_merge = pd.merge(fct_final[0], fct_final[1], how='outer', on =['yyyymmdd','area'])\n","\n","for i in range(2,7):\n","  pre_merge = pd.merge(pre_merge, fct_final[i], how='outer', on =['yyyymmdd','area'])\n","  \n","# 백병원데이터\n","back = pd.read_csv('/content/drive/MyDrive/2022_WeatherContest_Data/DataSet/final/final_res.csv',encoding='cp949')\n","back.drop(back.columns[4:],axis=1,inplace=True)\n","\n","# 이거 back['area'] 랑 pre_merge['area']랑 왜 다르냐?\n","def area_words(word):\n","        #1\n","    if word == '전북':\n","      word = '전북'\n","        #2\n","    elif word == '제주':\n","      word = '제주'\n","        #3\n","    elif word == '충남':\n","      word = '충남'\n","        #4\n","    elif word == '충북':\n","      word = '충북'\n","        #5\n","    elif word == '강원':\n","      word = '강원'\n","        #6\n","    elif word == '경기':\n","      word = '경기'\n","        #7\n","    elif word == '경남':\n","      word = '경남'\n","        #8\n","    elif word == '경북':\n","      word = '경북'\n","        #9\n","    elif word == '광주':\n","      word = '광주'\n","        #10\n","    elif word == '대구':\n","      word = '대구'\n","        #11\n","    elif word == '대전':\n","      word = '대전'\n","        #12\n","    elif word == '부산':\n","      word = '부산'\n","        #13\n","    elif word == '서울':\n","      word = '서울'\n","        #14\n","    elif word == '세종':\n","      word = '세종'\n","        #15\n","    elif word == '울산':\n","      word = '울산'\n","        #16\n","    elif word == '인천':\n","      word = '인천'\n","        #17\n","    elif word == '전남':\n","      word = '전남'\n","\n","    return word\n","pre_merge['area'] = [area_words(i) for i in pre_merge['area']]\n","back = pd.merge(back, pre_merge, how='outer', on =['yyyymmdd','area'])\n","\n","back.to_csv('/content/drive/MyDrive/2022_WeatherContest_Data/DataSet/final/fct_weather_merge.csv',encoding='cp949')"],"metadata":{"id":"r6CINvUhvaeZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659154705574,"user_tz":-540,"elapsed":560535,"user":{"displayName":"이윤신","userId":"01754473525638776627"}},"outputId":"1656d597-0cb7-4c7a-d47a-15412f85d8b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: FutureWarning: Passing 'suffixes' which cause duplicate columns {'val_x'} in the result is deprecated and will raise a MergeError in a future version.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:114: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}]}]}